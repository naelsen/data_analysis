---
title: "Projet Analyse de données"
author: "RAHBI Aissam & SENNOUN Naël"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 4
---

```{r, echo=FALSE}
# Reset de l'environnement
rm(list=ls())
# Import des librairies nécessaires pour les analyses.
library(FactoMineR)
library(MASS)
library(rmarkdown)
library(factoextra)
```


# Introduction des données


On voit que les deux premières colonnes (X & id) sont inutiles pour nos analyses, on va donc les supprimer.

```{r}
DF <- read.csv("data/train.csv")
# On supprime les lignes ou il y a des valeurs manquantes.
DF <- DF[!rowMeans(is.na(DF)*1) > 0,]
str(DF)
```

```{r}
# On retire les colonnes inutiles.
DF <- DF[,c(-1,-2)]
# On modifie le nom des lignes pour le style ;-)
row.names(DF) <- paste("n°", sep="", 1:dim(DF)[1]) 
# On renomme les colonnes pour avoir des noms moins longs (Utile pour l'affichage).
colnames(DF) <- c("Genre", "Fidélité", "Age", "Type.du.vol", "Classe", "Distance", "Wifi", "Horaire.pratique", "Facilité.resevation", "Emplacement.porte", "Nourriture", "Enregistrement.en.ligne", "Siege.confort", "Loisir", "On.board.service", "Espace.jambe", "Gestion.bagage", "Checkin.service", "Inflight.service", "Propreté", "Retard.depart", "Retard.arrivé", "Satisfaction")
```

Petit avant gout des données :

```{r, echo=FALSE}
paged_table(DF)
```

* Il y a autant d'hommes que de femmes dans notre jeu de données.

* Il y a une majorité de personnes qui voyagent pour une raison professionnelle que personnelle.

* Il y a beaucoup plus de clients loyaux que non loyaux.

* Les voyageurs en classe Éco Plus représentent une petite partie des voyageurs, quant aux classes business et éco ils en représentent un peu moins de la moitié.

* Pour finir, la proportion de voyageurs neutres ou insatisfaits et légèrement supérieure à celle des voyageurs satisfaits.

```{r, echo=FALSE}
par(fig=c(0,1/2,1/2,1))
pie(table(DF$Genre), col = c("pink","blue"),cex=0.8)
par(fig=c(0,1/2,0,1/2),new=TRUE)
pie(table(DF$Fidélité), col = c("red","green"),cex=0.8)
par(fig=c(1/2,1,1/2,1),new=TRUE)
pie(table(DF$Type.du.vol), col = rainbow(2), cex=0.8)
par(fig=c(1/2,1,0,1/2),new=TRUE)
pie(table(DF$Classe), col = rainbow(3),cex=0.8)
par(fig=c(1/3-1/5,2/3+1/5,1/3-1/5,2/3+1/5),new=TRUE)
pie(table(DF$Satisfaction), col=c("red","green"), cex=0.8)
```

Ci-dessous on voit que les notes sont assez homogènes, elles ont toutes :

* Un 1er quartile égal à 2 ou 3.

* Une médiane égal à 3 ou 4.

* Un 3-ème quartile égale à 4 ou 5.

* Les moyennes pour les notes vont de 2.73 à 3.64.

```{r, echo=FALSE}
summary(DF[,7:20])
```

On peut aussi observer les autres variables quantitatives :

* À vu d'oeil, l'âge suit une loi Gaussienne centrée autour de 40  (bien qu'elle ne prenne que des valeurs entières dans le jeu de données, la variable est Gaussienne dans la vraie vie).

* La distance est une variable qui possède quelques valeurs extrêmes au dessus de 4000km.

* Pour les retards il y a énormement de données abérrantes.

```{r,echo=FALSE}
par(mfrow=c(2,2))
boxplot(DF$Age, main="Âge")
points(mean(DF$Age), col='red')
boxplot(DF$Distance, main="Distance")
points(mean(DF$Distance), col='red')
boxplot(DF$Retard.depart, main="Retard depart")
points(mean(DF$Retard.depart), col='red')
boxplot(DF$Retard.arrivé, main="Retard arrivée")
points(mean(DF$Retard.arrivé), col='red')
```


# Analyse des données


## ACP


On récupère toutes les données quantitatives et la satisfaction.

```{r}
# On récupère Âge/Distance du vol/Retard Depart/Retard Arrivé (colonne 3/6/21/22), les notes (colonnes 7 à 20) et la satisfaction (colonne 23)
DF.tmp <- DF[,c(3,6,21,22,7:20,23)]
res.pca <- PCA(DF.tmp, quanti.sup=1:4, quali.sup=19, graph=FALSE)
```

Il est évident de penser que plus les notes attribuées par les voyageurs sont hautes et plus l'individu a de chance d'être satisfait, on peut le voir avec le graphe ci-dessous. Pour ne pas attribuer trop d'importance aux moyennes des notes des individus qui constituent un petit groupe, on associe une largeur par bande proportionnelle à la taille du groupe pour chaque moyenne attribuée.

```{r, echo=FALSE}
# On recupère les notes dans le dataframe, et on en fait la moyenne.
mean_notes <-rowMeans(DF[,7:20])
# Table de contingence pour les notes moyennes et la satisfaction.
tmp = table(as.factor(mean_notes),DF$Satisfaction)
barplot((tmp/rowSums(tmp))[,2], # Fréquence de satisfaction.
         width=rowSums(tmp),    # Taille des groupes.
         col=rainbow(n = dim(tmp)[1],alpha=0.8,start=0,end=0.4),
         main = "Fréquence de satisfaction en fonction de la moyenne des notes",
         xlab = "Note moyenne",
         ylab = "Pourcentage d'individus satisfaits")
```

Ainsi, on va faire notre ACP sur les notes.

***

**Les individus ou variables peuvent être proches dans le plan mais eloignés dans l'espace s'ils sont mal représentés dans le plan.**

Ainsi, il est important d'expliquer le modèle avec des variables bien representées dans le plan.
Pour cela on veillera à ne pas prendre les variables et individus ayant un cos2 trop bas. Ici on choisit un cos2 égale à 0.68 afin qu'il ne soit pas trop bas et qu'on ait au moins 3 variables à utiliser afin d'expliquer nos individus sur les axes 1 et 2.

Ici l'axe 1 va faire le contraste entre le confort à bord (droite) et l'inconfort (gauche), tandis que l'axe 2 fera le contraste entre les aspects techniques pour ce qui concerne le vol.

On peut voir que les variables quantitatives supplémentaires ne sont pas du tout interprétables (flèches en bleu) .

```{r}
plot(res.pca,select="cos2 0.68", choix="varcor")
```

**Lorsque l'angle entre deux axes est proche de 0°, les variables sont fortement corrélés positivement.**

**Lorsque l'angle est proche de 90°, les variables ne sont pas corrélés, ou très peu.**

**Lorsque l'angle est proche de 180°, les variables sont fortement corrélés négativement.**

* Ainsi, ci-dessus on voit que la facilité de reservation et le wifi sont fortement correlés.

* Loisir et Facilité.reservation ne le sont pas, ou très peu.

* Loisir et Wifi sont un peu corrélés positivement.

Verifions le :

Graphiquement (Facilité.resevation/Wifi) :

```{r,echo=FALSE}
boxplot(DF.tmp$Facilité.resevation ~ DF.tmp$Wifi,
        main = "Corrélation Facilité de reservation / Wifi",
        xlab = "Notes Wifi",
        ylab = "Facilité.reservation")
points(tapply(DF.tmp$Facilité.resevation, DF.tmp$Wifi, mean), col='red')
```

On remarque sur le boxplot qu'il semble y avoir une corrélation entre les notes attribuées à Wifi et à la Faclité de réservation, nous allons maintenant le vérifier.

**Test du chi-deux (Facilité.resevation/Wifi)** :

On rejette $H_0$ car p-value<0.5 , ainsi on peut affirmer avec un risque de se tromper de 5% que ces deux variables sont corrélés.

```{r}
chisq.test(DF.tmp$Facilité.resevation, DF.tmp$Wifi, simulate.p.value=TRUE)
```
Graphiquement on a pu voir qu'un passager donne, en moyenne, des notes égales à Facilité de reservation et Wifi.

***

Graphiquement (Loisir/Wifi) :

```{r,echo=FALSE}
boxplot(DF.tmp$Loisir ~ DF.tmp$Wifi,
        main = "Boxplot des notes Loisir / Wifi",
        xlab = "Notes Wifi",
        ylab = "Notes Loisir")
points(tapply(DF.tmp$Loisir, DF.tmp$Wifi, mean), col='red')
```

La corrélation entre Wifi et Loisir semble bien moins flagrante que celle vu précédemment, nous allons le  verifier.

**Test du Chi-deux (Loisir/Wifi) :**

On rejette $H_0$ car p-value<0.5 , ainsi on peut affirmer avec un risque de se tromper égal à 5% que ces deux variables sont corrélés.

```{r}
chisq.test(DF.tmp$Loisir, DF.tmp$Wifi, simulate.p.value=TRUE)
```

Graphiquement on a pu voir qu'un passager donne, en moyenne, des notes plus élevées au loisir quand il note bien le Wifi.

***

Graphiquement (Loisir/Facilité.reservation) :

```{r,echo=FALSE}
boxplot(DF.tmp$Loisir ~ DF.tmp$Facilité.resevation,
        main = "Boxplot des notes Loisir / Facilité reservation",
        xlab = "Notes Facilité de reservation",
        ylab = "Notes Loisir")
points(tapply(DF.tmp$Loisir, DF.tmp$Facilité.resevation, mean), col='red')
```

On vérifie une nouvelle fois la corrélation entre les deux variables.

**Chi-deux (Loisir/Facilité.resevartion) :**

On rejette $H_0$ car p-value<0.5 , ainsi on peut affirmer avec un risque de se tromper égal à 5% que ces deux variables sont corrélés.

```{r}
chisq.test(DF.tmp$Loisir, DF.tmp$Facilité.resevation , simulate.p.value=TRUE)
```

Le test du chi-deux montre que Loisir et Facilité.reservation sont corrélés, mais on peut voir graphiquement qu'elles ne le sont pas vraiment, on peut faire l'hypothèse que c'est parce qu'un passager qui met de bonnes notes en moyenne aura tendance à mettre de meilleures notes aux autres catégories, on peut faire le même raisonnement pour les mauvaises notes.

***

Ci-dessous on peut voir une nette séparation entre les individus satisfaits et non satisfaits. Les individus satisfaits sont ceux s'étant amusé. À l'inverse les individus non satisfaits ont octroyé des notes plus basses concernant les loisirs. On ne peut pas vraiment dire pour l'instant si la facilité de réservation et le wifi à bord influent sur la satisfaction du passager.

Ici par exemple l'individu n°70657 est satisfait, or il a mal noté les loisirs, le wifi et la facilité de réservation. Sa satisfaction est probablement influencée par d'autres variables, qui sont qualitatives. On se penchera sur ce sujet lors de l'ACM. 

```{r}
plot(res.pca,habillage=19, select="cos2 0.93", choix="ind",cex = 0.8)
```

L'individu qui contribue le plus à l'axe 1 y contribue à environ 0.01%.

```{r}
max(res.pca$ind$contrib[,1])
```

Il n'y a pas d'individus atypiques, ce qui est normal car nos données sont des notes comprises entre 0 et 5 et on a vu qu'elles étaient homogènes.

***

Premièrement, on peut voir  que les 3 premiers axes expliquent bien l'inertie sur les données : Les axes étant orthogonaux, ils expliquent 27.14% + 16.87% + 15.47% = 59.48% de l'inertie.

Quant aux axes 1 et 2, ils prennent en compte 27.14% + 16.87% = 44.01% du jeu de données.

On peut aussi voir que l'axe 2 et 3 expliquent à peu près autant l'un que l'autre l'inertie, ainsi on pourra aussi visualiser les données projetées sur le plan formé par l'axe 1 et 3 (voir 2 et 3).

```{r, echo=FALSE}
barplot(res.pca$eig[,2], col=rainbow(n=14,alpha=0.6,start=0,end=0.33),main="Pourcentage d'inertie expliquée par chaque axe", ylab="Contribution en %")
lines(seq(0.75,16.3,(16.3-0.75)/13),res.pca$eig[,2],type="b", xlim=c(0,max(res.pca$eig[,2])+10))
text(seq(0.75,16.3,(16.3-0.75)/13),res.pca$eig[,2]-1, paste(round(res.pca$eig[,2],2),"%"), cex=0.7)
```

On a un nouveau cercle de corrélation, ici on voit que :

* Le confort des sièges, la nourriture et la propreté sont fortement corrélés.

* La gestion des bagages et les services proposés sont fortement corrélés.

* Dans ce plan les loisirs sont presque totalement expliqués par l'axe 1.

* L'axe 3 oppose le "confort" aux services qui sont faiblement corrélés dû à l'angle proche de 90 degrés

```{r}
plot(res.pca, select="cos2 0.60", choix="varcor", axes = c(1,3))
```

Ci-dessous on voit donc que les passagers sont en général plus satisfait quand ils se sont amusé (loisirs), que le service était agréable (Gestion bagage, Inflight.service, On.board.service) et qu'ils ont passé un vol confortable (Siege.confort, nourriture, propreté), et inversement pour les passagers non satisfaits.

```{r}
plot(res.pca, habillage=19, select="cos2 0.9", cex=0.8, choix="ind", axes = c(1,3))
```

Ici on a le cercle de corrélation avec l'axe 2 et 3:

```{r}
plot(res.pca, select="cos2 0.6", choix="varcor", axes = c(2,3))
```

Il n'y a pas grand-chose à interpréter car le barycentre des voyageurs satisfaits et non satisfaits sont tout les 2 proches du centre de gravité de ce plan.

```{r}
plot(res.pca, invisible="ind", choix="ind", axes=c(2,3))
```


### Transformations & double centrage


Certains passagers ont attribué comme notes 0 pour certaines catégories du vol, on décide de ne pas faire de transformation par l'inverse car $\frac{1}{0}$ est un quotient indéterminé, ni de log-transformation car log(0) est indéterminé.


#### Transformation par racines carrée


On effectue la transformation ”double centrage” sur les données transformées par racine carrée afin de voir si on peut faire gagner en contribution les premières composantes afin d'être plus précis lors de nos analyses.

```{r}
DF.tmp <- sqrt(DF[,7:20])
DF.tmp <- t(scale(t(DF.tmp)))
res.pca <- PCA(DF.tmp, graph=FALSE)
barplot(res.pca$eig[,2], col=rainbow(n=14,alpha=0.6,start=0.66,end=1),
        main="Pourcentage d'intertie expliquée par chaque axe\n(Données transformées par racine carrée)",
        ylab="Contribution en %")
lines(seq(0.75,16.3,(16.3-0.75)/13), res.pca$eig[,2], type="b")
text(seq(0.75,16.3,(16.3-0.75)/13), res.pca$eig[,2]-1, paste(round(res.pca$eig[,2],2),"%"), cex=0.7)
```

Les transformations ne nous ont pas fait gagner plus d'informations au niveau des 2 premiers axes, on s'arrête là pour l'ACP.


### Conclusion ACP


Ici on a pu étudier l'impacte des variable quantitative sur la satisfaction des gens pour un trajet en avion.
Il en est ressorti que les services proposés dans l'avion et le confort à bord sont des aspects primordiaux pour la satisfaction des voyageurs.


## ACM


```{r}
DF.tmp<- DF[,c(1,2,4,5,23)]
paged_table(DF.tmp)
```

ACM 

```{r}
res.mca <- MCA(DF.tmp, quali.sup = 5, graph=FALSE)
```

D'abbord on peut observer que la première dimension influe à un peu plus de 30% quant à la 2, 3, 4 elles influent toutes autour de 20%.
Il sera donc surement nécessaire de s'intéresser à ces 4 dimensions.

```{r, echo=FALSE}
barplot(res.mca$eig[,2], col=rainbow(5))
```

```{r}
par(mfrow = c(2,2))
for(i in 1:4){
  barplot(res.mca$var$cos2[,i], las = 2, cex.names = 0.64, 
          col=rainbow(n=9,alpha=0.6,start=(i-1)/4,end=i/4),
          main=paste("Cos2 des modalités pour l'axe",i))
}
```

En se referent aux cos2 (cos2 > 0.7) des barplots précédents : 

L'axe 1 oppose les passagers qui voyagent pour le business et les passagers qui voyagent pour un motif personnel. Ceux qui voyagent pour le travail sont en général plus satisfaits et ceux qui voyagent pour un motif personnel sont en général sans avis ou insatisfaits.

L'axe 2 oppose les passagers loyaux aux non loyaux, il en résulte que le passagers non loyaux sont plus souvent insatisfaits et que les passagers loyaux.

Les 2 axes prennent aussi en compte a eux deux les voyageurs qui voyagent en business et en éco.

On peut voir que les voyageurs en éco sont plus souvent insatisfait de leur voyage que ceux en business classe.

```{r}
plot(res.mca, invisible="ind", axes=c(1,2))
```

En se referent aux cos2 (cos2 > 0.7) pour l'axe 3 des barplots précédents : 

On peut voir que l'axe 3 oppose les personnes de sexe different, on ne peut pas dire grand-chose quant à l'influence sur la satisfaction du client, on pourrait peut-être dire que les femmes sont un peu moins satisfaites mais c'est à vérifier.

```{r}
plot(res.mca, invisible="ind", axes=c(1,3))
```

Pour prendre en compte les voyageurs classe éco plus on visualise sur le plan formé par l'axe 3 et 4

On peut voir ici que les voyageurs en classe Éco Plus sont moins satisfaits de leur voyages, ils sont très excentrés car ils représentes des données inhabituelles.


```{r}
plot(res.mca, invisible="ind", axes=c(3,4))
```

Rappelez-vous de l'individu n°70657, il était satisfait de son vol malgré les mauvaises notes attribués aux différentes catégories. On voit qu'il possède toutes les modalités influant positivement sur la satisfaction. Ceci montre bien que l'analyse des données qualitatives est importante car on a eu des informations qu'on ne pouvait pas avoir avec l'ACP.

```{r, echo=FALSE}
paged_table(DF.tmp[70657,])
```


### Conclusion


D'après l'ACM :

* Si un passager voyage pour des raisons personnelles, il a moins de chance d'être satisfait du vol qu'un passager qui voyage pour le business.

* Si le passager est un client fidèle (Loyal custommer) il a plus de chance d'être satisfait du vol qu'un passager qui est déloyal (Disloyal custommer).

* Si un voyageur est en classe business, cela influera positivement sur sa satisfaction, alors que s'il est en classe Eco cela influera négativement. Les passagers Éco plus sont particuliers, mais le fait d'être en classe Éco plus influe négativement sur leur satisfaction.

* Le sexe de l'individu n'a pas l'air d'influer significativement sur la satisfaction, mais on peut faire l'hypothèse que les femmes sont moins satisfaites que les hommes.


## Clustering 
On peut dicerner 4 types de catégorie d'âge :

* 7-19 ans
* 20-38 ans
* 39-60 ans
* 61+ ans

```{r, echo=FALSE}
tab = table(data.frame(DF$Age,DF$Satisfaction))
barplot(tab[,2]/(tab[,1]+tab[,2]),
        width=tab[,1]+tab[,2],
        col=rainbow(80),
        xlab="Age",
        ylab="Fréquence de Satisfaction",
        main="Fréquence de satisfaction selon l'age")
```

```{r, echo=FALSE}
change_age <- function(x){
  if(7 < x && x <= 19)
    return("7-19")
  else if(19 < x && x <= 38)
    return("20-38")
  else if(38 < x && x <= 60)
    return("39-60")
  else
    return("61+")
}

DF.tmp = DF[,c(2:5)]
DF.tmp$Age = paste(lapply(DF.tmp$Age,change_age))
```

On a un nouveau dataframe pour les variables qualitatives qui nous serviront a la creation des profils:

```{r, echo=FALSE}
paged_table(DF.tmp)
```

Nous allons maintenant regrouper les individus par groupes en utilisant les différentes méthodes de clustering. Il n'y aura pas grand intérêt à les réaliser sur l'ensemble des individus, nous allons donc modifier le jeu de données afin d'analyser les données en fonction des "profils" d'individus. On pourra de cette manière déterminer quels sont les profils les plus proches en terme de notation, et de satisfaction.

```{r,echo=FALSE}
profils = data.frame(table(DF.tmp))
```

On ne garde que les profils qui compte plus de 30 personnes afin que le profils soit intéréssant a analyser.
On compte maintenant 68 profils.
```{r, echo=FALSE}
profils = profils[profils[,5]>=30,]
row.names(profils) = paste(1:dim(profils)[1])
paged_table(profils)
```

```{r, echo=FALSE}
profils = paste(profils[,1], profils[,2], profils[,3], profils[,4], sep="/")
#DF.notes = DF[,c(9,11,14,17)]
DF.notes = DF[,7:20]
#col_name = colnames(DF.notes)
#DF.notes = data.frame(DF.notes,(DF[,23]=="satisfied")*1)
#colnames(DF.notes) = c(col_name,"satisfied")
col_name = colnames(DF.notes)
DF.notes = cbind(paste(DF.tmp[,1], DF.tmp[,2], DF.tmp[,3], DF.tmp[,4], sep="/"), DF.notes)
colnames(DF.notes) = c("profil", col_name)
```

On fait la moyenne des notes de chaque catégories :

```{r,echo=FALSE}
bool_profil = DF.notes$profil %in% profils
DF.notes=DF.notes[bool_profil,]
DF.agg=aggregate.data.frame(x=DF.notes[,-1], by=list(DF.notes$profil), FUN=mean)[,-1]
row.names(DF.agg)=profils
paged_table(DF.agg)
```


### Hierarchique


Ainsi, on peut commencer notre clustering.

$K=6$ semble on bon compromis.

```{r}
K=6
DF.agg.dist = dist(DF.agg, method="euclidean") # "manhattan" (L1), "euclidean" (L2), "maximum" (L.infini), "minkowski", p = truc (L.truc)
cah.ward = hclust(DF.agg.dist, method="ward.D2")
par(cex.main=2, cex=0.2)
plot(cah.ward, hang=-1)
rect.hclust(cah.ward,K)
```

On a donc réussis a créer 6 groupes de profils similaire sur les 68 profils qu'on est en train d'étudier.

Penchons nous sur la composition de ces groupes :

```{r}
groupes.cah <-cutree(cah.ward, K)
paged_table(data.frame(sort(groupes.cah)))
```

*Le groupe 1 rassemble des individus en business classe.

*Le groupe 2 réunit les individus en business classe voyageant pour le business.

*Le groupe 3 regroupe les clients fidèles.

*Le groupe 4 est particulier et rassemble seulement deux profils, en particulier, des profils déloyaux qui voyagent en classe éco.

*Le groupe 5 réunit des passagers majoritairement en dessous de 39 ans voyageant en classe éco ou éco plus.

*Le groupe 6 regroupe les passagers de 39 ans et plus, voyageant en éco ou éco plus.

***

```{r}
groupes.cah <-cutree(cah.ward, K)
Means_groupes.cah <- matrix(NA, nrow=K, ncol=dim(DF.notes)[2])
colnames(Means_groupes.cah)=c(colnames(DF.notes[,-1]),"satisfied")
rownames(Means_groupes.cah)= paste("Groupe",1:K,sep="_")
DF.tmp = data.frame(DF.notes,(DF[bool_profil,23]=="satisfied")*1)
for (i in 1:K) Means_groupes.cah[i,] <- colMeans(DF.tmp[DF.tmp$profil %in% rownames(data.frame(groupes.cah[groupes.cah==i])),][,-1])
paged_table(data.frame(Means_groupes.cah))
```



Le clustering hiérarchique nous permet de determiner le nombre de groupes idéal : $K = 6$. Les notes attribuées selon les différentes groupes ne sont pas significativement différentes.


### Kmeans

On réalise ensuite le Kmeans, avec le meme nombre de groupes qu'avec le CAH.

```{r}
Means_groupes.kmeans <- matrix(NA, nrow=K, ncol=dim(DF.notes)[2])
res.kmeans = kmeans(DF.agg, centers=Means_groupes.cah[,-15])
for (i in 1:K) Means_groupes.kmeans[i,] <- colMeans(DF.tmp[DF.tmp$profil %in% rownames(data.frame(res.kmeans$cluster[res.kmeans$cluster==i])),][,-1])

colnames(Means_groupes.kmeans)=c(colnames(DF.notes[,-1]),"satisfied")
rownames(Means_groupes.kmeans)= paste("Groupe",1:K,sep="_")
groupes.kmeans = res.kmeans$cluster
DF.tmp = data.frame(DF.notes,(DF[bool_profil,23]=="satisfied")*1)
for (i in 1:K) Means_groupes.kmeans[i,] <- colMeans(DF.tmp[DF.tmp$profil %in% rownames(data.frame(groupes.kmeans[groupes.kmeans==i])),][,-1])

paged_table(data.frame(Means_groupes.kmeans))
```

```{r}
table(groupes.cah,groupes.kmeans)
```

### Visualisation 

On représente les clusters en 2D à l'aide des composantes principales. On remarque que certains clusters se chevauchent
```{r}
fviz_cluster(res.kmeans, data = DF.agg,
             palette = rainbow(K), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw(),
             main = "Kmeans : Représentation des clusters")
```


